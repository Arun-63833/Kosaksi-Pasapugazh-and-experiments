{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install dill\n",
        "\n",
        "!pip install ultralytics\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "1ueaGMByTE5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ActivationExtractor:\n",
        "    def __init__(self, layer_name):\n",
        "        self.layer_name = layer_name\n",
        "        self.activation = None\n",
        "\n",
        "    def hook_fn(self, module, input, output):\n",
        "        self.activation = output.detach()\n",
        "\n",
        "def get_layer_activation(model, layer_name, image):\n",
        "    extractor = ActivationExtractor(layer_name)\n",
        "\n",
        "    for name, module in model.named_modules():\n",
        "        if name == layer_name:\n",
        "            module.register_forward_hook(extractor.hook_fn)\n",
        "            break\n",
        "\n",
        "    image_tensor = torch.from_numpy(np.array(image).transpose(2, 0, 1)).float().unsqueeze(0) / 255.0\n",
        "    image_tensor = image_tensor.to(next(model.parameters()).device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model(image_tensor)\n",
        "\n",
        "    return extractor.activation\n",
        "\n",
        "def visualize_activation(image, activation, layer_name):\n",
        "    # Sum across channels and normalize\n",
        "    activation_sum = activation.sum(dim=1).squeeze()\n",
        "    activation_normalized = (activation_sum - activation_sum.min()) / (activation_sum.max() - activation_sum.min())\n",
        "\n",
        "    # Resize activation to match image size\n",
        "    activation_resized = torch.nn.functional.interpolate(\n",
        "        activation_normalized.unsqueeze(0).unsqueeze(0),\n",
        "        size=image.size[::-1],\n",
        "        mode='bilinear',\n",
        "        align_corners=False\n",
        "    ).squeeze()\n",
        "\n",
        "    # Convert to numpy for matplotlib\n",
        "    activation_np = activation_resized.cpu().numpy()\n",
        "\n",
        "    # Create the visualization\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(activation_np, cmap='jet')\n",
        "    plt.title(f'Activation Heatmap ({layer_name})')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(image)\n",
        "    plt.imshow(activation_np, cmap='jet', alpha=0.5)\n",
        "    plt.title('Heatmap Overlay')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model_after_attention = YOLO('/content/best (4).pt')\n",
        "model_just_modified=YOLO('/content/MODIFIED.pt')\n",
        "model_org=YOLO('/content/original.pt')\n",
        "# Load the image\n",
        "image_path = '/content/drive/MyDrive/Dogcat.v1i.yolov8/test/images/videoplayback_mp4-0_jpg.rf.cc044ba7afd1afff104a1edb2f028c2b.jpg'\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "# Choose the layer name you want to extract activations from\n",
        "layer_name = 'model.30.cv3.3.1.conv'  # Example: a specific conv layer\n",
        "\n",
        "# Get activations\n",
        "activation_after_attention = get_layer_activation(model_after_attention.model, layer_name, image)\n",
        "activation_after_modification = get_layer_activation(model_just_modified.model, layer_name, image)\n",
        "activation_original=get_layer_activation(model_org.model, layer_name, image)\n",
        "\n",
        "# Visualize the activation\n",
        "visualize_activation(image, activation_original, layer_name)\n",
        "visualize_activation(image, activation_after_modification, layer_name)\n",
        "visualize_activation(image, activation_after_attention, layer_name)"
      ],
      "metadata": {
        "id": "npkYHOgYKNq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rigvedrs/YOLO-V8-CAM/\n",
        "yolo_cam_parent_dir = '/content/YOLO-V8-CAM'\n",
        "sys.path.append(yolo_cam_parent_dir)\n"
      ],
      "metadata": {
        "id": "acalIcy-zMiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yolo_cam.utils.svd_on_activations import get_2d_projection\n",
        "from yolo_cam.eigen_cam import EigenCAM\n",
        "from yolo_cam.utils.image import show_cam_on_image, scale_cam_image"
      ],
      "metadata": {
        "id": "SE8cK5XtzSul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5stuDwbtU4a"
      },
      "outputs": [],
      "source": [
        "m=[i for i in range(2,15)]\n",
        "l=os.listdir('/content/drive/MyDrive/Dogcat.v1i.yolov8/test/images')\n",
        "\n",
        "for i in l:\n",
        "  img = cv2.imread('/content/drive/MyDrive/Dogcat.v1i.yolov8/test/images/'+i)\n",
        "  img = cv2.resize(img, (256, 256))\n",
        "  rgb_img = img.copy()\n",
        "  img = np.float32(img) / 255\n",
        "  rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  plt.imshow(rgb_img)\n",
        "  print('original')\n",
        "  plt.show()\n",
        "  for j in m:\n",
        "    model = YOLO('/content/yolov8n.pt')\n",
        "    target_layers =[model.model.model[-j]]\n",
        "    cam = EigenCAM(model, target_layers,task='od')\n",
        "    grayscale_cam = cam(rgb_img)[0, :, :]\n",
        "    cam_image = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
        "    plt.imshow(cam_image)\n",
        "    print('modified')\n",
        "    plt.show()"
      ]
    }
  ]
}